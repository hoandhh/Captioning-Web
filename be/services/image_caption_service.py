# services/image_caption_service.py
import torch
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import os
from googletrans import Translator
from gtts import gTTS
import tempfile
import playsound
import io

class ImageCaptionService:
    """
    L·ªõp n√†y ch·ªãu tr√°ch nhi·ªám:
    - Load m√¥ h√¨nh BLIP v√† Processor t·ª´ local (m·ªôt l·∫ßn duy nh·∫•t).
    - Cung c·∫•p h√†m generate_caption() nh·∫≠n file ·∫£nh t·ª´ controller, tr·∫£ v·ªÅ chu·ªói caption.
    - N·∫øu b·∫≠t speak=True: d·ªãch ch√∫ th√≠ch sang ti·∫øng Vi·ªát v√† ph√°t √¢m thanh.
    """

    _model = None
    _processor = None
    _device = "cuda" if torch.cuda.is_available() else "cpu"

    # ƒê∆∞·ªùng d·∫´n m√¥ h√¨nh
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.abspath(os.path.join(current_dir, ".."))
    _model_path = os.path.join(parent_dir, "pretrain", "blip_trained")

    _is_loading = False
    _translator = Translator()  # T√°i s·ª≠ d·ª•ng translator

    @classmethod
    def _load_model_if_needed(cls):
        if cls._model is None or cls._processor is None:
            if cls._is_loading:
                import time
                while cls._is_loading and (cls._model is None or cls._processor is None):
                    time.sleep(0.5)
                return

            cls._is_loading = True
            try:
                if not os.path.exists(cls._model_path):
                    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng d·∫´n m√¥ h√¨nh: {cls._model_path}")

                print(f"ƒêang t·∫£i m√¥ h√¨nh BLIP t·ª´ {cls._model_path}...")
                cls._processor = BlipProcessor.from_pretrained(cls._model_path, use_fast=True)
                cls._model = BlipForConditionalGeneration.from_pretrained(cls._model_path)
                cls._model = cls._model.to(cls._device)
                cls._model.eval()
                print(f"T·∫£i m√¥ h√¨nh th√†nh c√¥ng tr√™n thi·∫øt b·ªã {cls._device}")
            finally:
                cls._is_loading = False

    @classmethod
    def unload_model(cls):
        if cls._model is not None:
            cls._model = None
            cls._processor = None
            import gc
            gc.collect()
            if cls._device == "cuda":
                torch.cuda.empty_cache()
            print("ƒê√£ gi·∫£i ph√≥ng m√¥ h√¨nh kh·ªèi b·ªô nh·ªõ")

    @classmethod
    def speak_caption(cls, text_en):
        """
        D·ªãch vƒÉn b·∫£n ti·∫øng Anh sang ti·∫øng Vi·ªát v√† ph√°t √¢m.
        """
        try:
            translation = cls._translator.translate(text_en, src='en', dest='vi')
            caption_vi = translation.text
            print("üîÅ D·ªãch sang ti·∫øng Vi·ªát:", caption_vi)

            tts = gTTS(caption_vi, lang='vi')
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
                temp_path = fp.name
                tts.save(temp_path)

            try:
                playsound.playsound(temp_path)
            except Exception:
                os.system(f"start {temp_path}")
            finally:
                os.remove(temp_path)
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi ƒë·ªçc caption: {e}")

    @classmethod
    def generate_caption_from_binary(cls, image_data, max_length=30, num_beams=5, speak=False):
        """
        T·∫°o caption cho ·∫£nh t·ª´ d·ªØ li·ªáu nh·ªã ph√¢n.
        N·∫øu speak=True, s·∫Ω d·ªãch caption sang ti·∫øng Vi·ªát v√† ph√°t ti·∫øng.
        """
        try:
            cls._load_model_if_needed()

            # Chuy·ªÉn d·ªØ li·ªáu nh·ªã ph√¢n th√†nh ƒë·ªëi t∆∞·ª£ng PIL Image
            image = Image.open(io.BytesIO(image_data)).convert("RGB")
            inputs = cls._processor(image, return_tensors="pt")
            for k, v in inputs.items():
                inputs[k] = v.to(cls._device)

            with torch.no_grad():
                output_ids = cls._model.generate(
                    **inputs,
                    max_length=max_length,
                    num_beams=num_beams,
                    min_length=5
                )

            caption_en = cls._processor.decode(output_ids[0], skip_special_tokens=True)
            print("üì∏ Caption ti·∫øng Anh:", caption_en)

            if speak:
                cls.speak_caption(caption_en)

            return caption_en

        except Exception as e:
            print(f"L·ªói khi t·∫°o caption: {e}")
            raise
            
    @classmethod
    def generate_caption_from_image_id(cls, image_id, max_length=30, num_beams=5, speak=False):
        """
        T·∫°o caption cho ·∫£nh t·ª´ ID c·ªßa ·∫£nh trong MongoDB.
        """
        from models.image import Image
        
        image_doc = Image.objects(id=image_id).first()
        if not image_doc:
            raise ValueError("Kh√¥ng t√¨m th·∫•y ·∫£nh v·ªõi ID cung c·∫•p")
            
        return cls.generate_caption_from_binary(image_doc.image_data, max_length, num_beams, speak)