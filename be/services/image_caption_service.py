# services/image_caption_service.py
import torch
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import os
from googletrans import Translator
from gtts import gTTS
import tempfile
import playsound  

class ImageCaptionService:
    """
    L·ªõp n√†y ch·ªãu tr√°ch nhi·ªám:
    - Load m√¥ h√¨nh BLIP v√† Processor t·ª´ local (m·ªôt l·∫ßn duy nh·∫•t).
    - Cung c·∫•p h√†m generate_caption() nh·∫≠n file ·∫£nh t·ª´ controller, tr·∫£ v·ªÅ chu·ªói caption.
    """

    # C√°c thu·ªôc t√≠nh "static" ƒë·ªÉ gi·ªØ m√¥ h√¨nh, processor, thi·∫øt b·ªã
    _model = None
    _processor = None
    _device = "cuda" if torch.cuda.is_available() else "cpu"
    # _model_path = "D:/AIRC/AIRC-Backend/pretrain/blip_trained"
    
    current_dir = os.path.dirname(os.path.abspath(__file__))  # L·∫•y th∆∞ m·ª•c hi·ªán t·∫°i (services)
    parent_dir = os.path.abspath(os.path.join(current_dir, ".."))  # L√πi l√™n m·ªôt c·∫•p (AIRC-Backend)
    _model_path = os.path.join(parent_dir, "pretrain", "blip_trained")  # ƒê∆∞·ªùng d·∫´n ƒë·∫øn pretrain/blip_trained
    
    _is_loading = False  # NgƒÉn ch·∫∑n c√°c n·ªó l·ª±c t·∫£i ƒë·ªìng th·ªùi

    @classmethod
    def _load_model_if_needed(cls):
        """
        H√†m n·ªôi b·ªô, ch·ªâ load model v√† processor m·ªôt l·∫ßn.
        Gi√∫p tr√°nh vi·ªác load m√¥ h√¨nh nhi·ªÅu l·∫ßn g√¢y ch·∫≠m h·ªá th·ªëng.
        """
        if cls._model is None or cls._processor is None:
            if cls._is_loading:
                # ƒê·ª£i n·∫øu m·ªôt lu·ªìng kh√°c ƒëang t·∫£i
                import time
                while cls._is_loading and (cls._model is None or cls._processor is None):
                    time.sleep(0.5)
                return
                
            cls._is_loading = True
            try:
                if not os.path.exists(cls._model_path):
                    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng d·∫´n m√¥ h√¨nh: {cls._model_path}")
                    
                print(f"ƒêang t·∫£i m√¥ h√¨nh BLIP t·ª´ {cls._model_path}...")
                cls._processor = BlipProcessor.from_pretrained(cls._model_path, use_fast=True)
                cls._model = BlipForConditionalGeneration.from_pretrained(cls._model_path)
                cls._model = cls._model.to(cls._device)
                cls._model.eval()
                print(f"T·∫£i m√¥ h√¨nh th√†nh c√¥ng tr√™n thi·∫øt b·ªã {cls._device}")
            finally:
                cls._is_loading = False

    @classmethod
    def unload_model(cls):
        """
        Gi·∫£i ph√≥ng m√¥ h√¨nh ƒë·ªÉ gi·∫£i ph√≥ng b·ªô nh·ªõ GPU khi c·∫ßn
        """
        if cls._model is not None:
            cls._model = None
            cls._processor = None
            # B·∫Øt bu·ªôc thu gom r√°c
            import gc
            gc.collect()
            if cls._device == "cuda":
                torch.cuda.empty_cache()
            print("ƒê√£ gi·∫£i ph√≥ng m√¥ h√¨nh kh·ªèi b·ªô nh·ªõ")

    @classmethod
    def generate_caption_from_path(cls, image_path, max_length=30, num_beams=5, speak=False):
        """
        T·∫°o caption cho ·∫£nh t·ª´ ƒë∆∞·ªùng d·∫´n file.
        N·∫øu speak=True, s·∫Ω d·ªãch caption sang ti·∫øng Anh v√† ph√°t ti·∫øng.
        """
        if not os.path.exists(image_path):
            raise ValueError("Kh√¥ng t√¨m th·∫•y file ·∫£nh")

        try:
            cls._load_model_if_needed()
            image = Image.open(image_path).convert("RGB")
            inputs = cls._processor(image, return_tensors="pt")
            for k, v in inputs.items():
                inputs[k] = v.to(cls._device)

            with torch.no_grad():
                output_ids = cls._model.generate(
                    **inputs,
                    max_length=max_length,
                    num_beams=num_beams,
                    min_length=5
                )

            caption_vi = cls._processor.decode(output_ids[0], skip_special_tokens=True)
            print("üì∏ Caption ti·∫øng Vi·ªát:", caption_vi)

            if speak:
                translator = Translator()
                translation = translator.translate(caption_vi, src='en', dest='vi')
                caption_en = translation.text
                print("üîÅ D·ªãch sang ti·∫øng Anh:", caption_en)

                # Chuy·ªÉn vƒÉn b·∫£n ti·∫øng Anh th√†nh ti·∫øng n√≥i
                tts = gTTS(caption_en, lang='vi')
                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
                    temp_path = fp.name
                    tts.save(temp_path)

                # Ph√°t √¢m thanh
                try:
                    playsound.playsound(temp_path)
                except Exception:
                    os.system(f"start {temp_path}")  # fallback n·∫øu playsound l·ªói

                # X√≥a file t·∫°m (tu·ª≥ ch·ªçn)
                os.remove(temp_path)

            return caption_vi

        except Exception as e:
            print(f"L·ªói khi t·∫°o caption: {e}")
            raise
